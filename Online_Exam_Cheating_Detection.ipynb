{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoha87222/online-exam-cheating-detection/blob/main/Online_Exam_Cheating_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XJoXWoe1yfR",
        "outputId": "d85367bb-8b41-48b4-b326-cf9e0d35c3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️  Downloading YOLOv8n model...\n",
            "✅ YOLOv8n model downloaded and saved to models/yolov8n.pt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Create the models directory if it doesn't exist\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# URL of the YOLOv8n model file\n",
        "url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\"\n",
        "destination = \"models/yolov8n.pt\"\n",
        "\n",
        "# Download the model\n",
        "print(\"⬇️  Downloading YOLOv8n model...\")\n",
        "urllib.request.urlretrieve(url, destination)\n",
        "print(\"✅ YOLOv8n model downloaded and saved to models/yolov8n.pt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O blaze_face_short_range.tflite https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite\n"
      ],
      "metadata": {
        "id": "tX7EMjvS7l_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O face_landmarker_v2_with_blendshapes.task https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\n"
      ],
      "metadata": {
        "id": "j7XH4e287qcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "sYOXsbVjoN3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727f4538-053e-479d-eec0-6f4fcd9c2993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.31)\n",
            "Requirement already satisfied: absl-py~=2.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mediapipe) (2.0.2)\n",
            "Requirement already satisfied: sounddevice~=0.5 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: flatbuffers~=25.9 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.12.19)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice~=0.5->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice~=0.5->mediapipe) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ultralytics"
      ],
      "metadata": {
        "id": "esKvq4OxoUe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0fd7c4-8c19-43c4-c3f8-d84ef6be0808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.253)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "YOLO_MODEL_PATH = 'yolov8n.pt'\n",
        "\n",
        "if uploaded:\n",
        "\n",
        "    VIDEO_PATH = list(uploaded.keys())[0]\n",
        "    print(f\"File uploaded successfully: {VIDEO_PATH}\")\n",
        "else:\n",
        "    print(\"No File Uploaded\")\n",
        "\n",
        "\n",
        "MAX_YAW_DEG = 35\n",
        "MAX_PITCH_DEG = 25\n",
        "\n",
        "\n",
        "yolo_model = YOLO(YOLO_MODEL_PATH)\n",
        "away_count = 0\n",
        "phone_detected_count = 0\n",
        "unauthorized_person_detected_count = 0\n",
        "calibrated_pitch, calibrated_yaw = 0, 0\n",
        "detected_object_types = set()\n",
        "\n",
        "\n",
        "model_points = np.array([\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (0.0, -330.0, -65.0),\n",
        "    (-225.0, 170.0, -135.0),\n",
        "    (225.0, 170.0, -135.0),\n",
        "    (-150.0, -150.0, -125.0),\n",
        "    (150.0, -150.0, -125.0)\n",
        "], dtype=np.float64)\n",
        "\n",
        "\n",
        "base_options_land = python.BaseOptions(model_asset_path='/content/face_landmarker_v2_with_blendshapes.task')\n",
        "options_land = vision.FaceLandmarkerOptions(\n",
        "    base_options=base_options_land,\n",
        "    running_mode=vision.RunningMode.IMAGE,\n",
        "    num_faces=2\n",
        ")\n",
        "\n",
        "def estimate_head_pose(landmarks, width, height):\n",
        "\n",
        "    image_points = np.array([\n",
        "        (landmarks[1].x * width, landmarks[1].y * height),\n",
        "        (landmarks[152].x * width, landmarks[152].y * height),\n",
        "        (landmarks[33].x * width, landmarks[33].y * height),\n",
        "        (landmarks[263].x * width, landmarks[263].y * height),\n",
        "        (landmarks[61].x * width, landmarks[61].y * height),\n",
        "        (landmarks[291].x * width, landmarks[291].y * height)\n",
        "    ], dtype=np.float64)\n",
        "\n",
        "    focal_length = width\n",
        "    center = (width / 2, height / 2)\n",
        "    camera_matrix = np.array([[focal_length, 0, center[0]], [0, focal_length, center[1]], [0, 0, 1]], dtype=np.float64)\n",
        "    dist_coeffs = np.zeros((4, 1))\n",
        "\n",
        "    success, rot_vec, trans_vec = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
        "    if not success: return None\n",
        "\n",
        "    rmat, _ = cv2.Rodrigues(rot_vec)\n",
        "    angles, _, _, _, _, _ = cv2.RQDecomp3x3(rmat)\n",
        "    return angles\n",
        "\n",
        "def convert_frame(frame):\n",
        "    return mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "with vision.FaceLandmarker.create_from_options(options_land) as landmarker:\n",
        "\n",
        "\n",
        "    print(\"Calibrating... Please look directly at the camera.\")\n",
        "    calibration_data = []\n",
        "    while len(calibration_data) < 30:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "        mp_img = convert_frame(frame)\n",
        "        res = landmarker.detect(mp_img)\n",
        "        if res.face_landmarks:\n",
        "            angles = estimate_head_pose(res.face_landmarks[0], frame.shape[1], frame.shape[0])\n",
        "            if angles: calibration_data.append(angles[:2])\n",
        "\n",
        "    if calibration_data:\n",
        "        calibrated_pitch, calibrated_yaw = np.mean(calibration_data, axis=0)\n",
        "        print(f\"Calibration Complete: Pitch {calibrated_pitch:.2f}, Yaw {calibrated_yaw:.2f}\")\n",
        "\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "\n",
        "        h, w, _ = frame.shape\n",
        "        mp_img = convert_frame(frame)\n",
        "        land_res = landmarker.detect(mp_img)\n",
        "\n",
        "\n",
        "        looking_away = False\n",
        "        multi_face = False\n",
        "\n",
        "\n",
        "        if land_res.face_landmarks:\n",
        "            num_faces = len(land_res.face_landmarks)\n",
        "            if num_faces > 1:\n",
        "                unauthorized_person_detected_count += 1\n",
        "                multi_face = True\n",
        "\n",
        "\n",
        "            angles = estimate_head_pose(land_res.face_landmarks[0], w, h)\n",
        "            if angles:\n",
        "                p_diff = abs(angles[0] - calibrated_pitch)\n",
        "                y_diff = abs(angles[1] - calibrated_yaw)\n",
        "                if p_diff > MAX_PITCH_DEG or y_diff > MAX_YAW_DEG:\n",
        "                    away_count += 1\n",
        "                    looking_away = True\n",
        "\n",
        "\n",
        "        y_res = yolo_model(frame, verbose=False, conf=0.4)\n",
        "        phone_present = False\n",
        "        for r in y_res:\n",
        "            for box in r.boxes:\n",
        "                cls = r.names[int(box.cls[0])]\n",
        "                if cls in [\"cell phone\", \"book\"]:\n",
        "                    phone_detected_count += 1\n",
        "                    phone_present = True\n",
        "                    detected_object_types.add(cls)\n",
        "                    b = box.xyxy[0].cpu().numpy().astype(int)\n",
        "                    cv2.rectangle(frame, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "        if looking_away: cv2.putText(frame, \"GAZE VIOLATION\", (30, 50), 2, 0.8, (0, 0, 255), 2)\n",
        "        if multi_face: cv2.putText(frame, \"MULTIPLE PEOPLE\", (30, 80), 2, 0.8, (0, 0, 255), 2)\n",
        "        if phone_present: cv2.putText(frame, \"OBJECT PROHIBITED\", (30, 110), 2, 0.8, (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "\n",
        "cap.release()\n",
        "print(f\"\\n--- Final Proctoring Report ---\")\n",
        "\n",
        "\n",
        "gaze_status = \"Yes\" if away_count > 0 else \"No\"\n",
        "object_status = \"Yes\" if phone_detected_count > 0 else \"No\"\n",
        "person_status = \"Yes\" if unauthorized_person_detected_count > 0 else \"No\"\n",
        "object_list = \", \".join(detected_object_types) if detected_object_types else \"N/A\"\n",
        "\n",
        "print(f\"Gaze Violation Detected: {gaze_status}\")\n",
        "print(f\"Unauthorized Object Detected: {object_status} ({object_list})\")\n",
        "print(f\"Multiple Person Violation: {person_status}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "2jSWgwXtIQpD",
        "outputId": "fa6e6871-6a3b-49d7-f90c-850473183d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'audio_classifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2121519594.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mediapipe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageFormat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mediapipe/tasks/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mediapipe/tasks/python/audio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mAudioClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mAudioClassifierOptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifierOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mAudioClassifierResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifierResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
          ]
        }
      ]
    }
  ]
}